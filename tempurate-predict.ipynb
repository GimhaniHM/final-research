{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import joblib\n",
    "import logging\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# LOGGING & CONFIGURATION\n",
    "# ------------------------------------------------------------------------\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "\n",
    "CONFIG = {\n",
    "    \"csv_path\": \"/kaggle/input/tem-dataset/city_base_Tem.csv\",  # <-- Update to your CSV\n",
    "    \"output_dir\": \"forecasts\",\n",
    "    \"model_dir\": \"models\",\n",
    "    \"initial\": \"365 days\",\n",
    "    \"period\": \"180 days\",\n",
    "    \"horizon\": \"90 days\",\n",
    "    \"max_lag\": 3,\n",
    "    \"prophet_param_grid\": {\n",
    "        \"changepoint_prior_scale\": [0.05, 0.1, 0.2],\n",
    "        \"seasonality_mode\": [\"additive\", \"multiplicative\"]\n",
    "    },\n",
    "    \"rf_param_dist\": {\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"max_depth\": [3, 5, 7, 10, None],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"max_features\": [\"sqrt\", \"log2\", None]\n",
    "    },\n",
    "    \"n_iter_rf_random_search\": 10,\n",
    "    \"cv_splits\": 3,\n",
    "    \"random_state\": 42,\n",
    "    \"target_year\": 2026,\n",
    "    # We will forecast each of these three columns in a loop\n",
    "    \"temp_columns\": [\n",
    "        \"temperature_2m_mean (°C)\",\n",
    "        \"temperature_2m_max (°C)\",\n",
    "        \"temperature_2m_min (°C)\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "os.makedirs(CONFIG[\"model_dir\"], exist_ok=True)\n",
    "os.makedirs(CONFIG[\"output_dir\"], exist_ok=True)\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# DATA LOADING FUNCTION\n",
    "# ------------------------------------------------------------------------\n",
    "def load_data_multi_city(csv_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads CSV with columns:\n",
    "      city_name, date, temperature_2m_mean (°C), temperature_2m_max (°C), temperature_2m_min (°C)\n",
    "    Renames 'date' -> 'ds' so Prophet can recognize it, but does NOT pick any single column as 'y' yet.\n",
    "    We'll do that when we loop over each target column.\n",
    "    \"\"\"\n",
    "    LOGGER.info(f\"Loading data from {csv_path} ...\")\n",
    "    if not os.path.isfile(csv_path):\n",
    "        raise FileNotFoundError(f\"Could not find file: {csv_path}\")\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Check required columns\n",
    "    required_cols = [\n",
    "        'city_name', \n",
    "        'date', \n",
    "        'temperature_2m_mean (°C)', \n",
    "        'temperature_2m_max (°C)', \n",
    "        'temperature_2m_min (°C)'\n",
    "    ]\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"CSV missing columns: {missing_cols}\")\n",
    "\n",
    "    # Convert date to datetime\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "\n",
    "    # Drop rows with invalid city_name or date\n",
    "    null_mask = df['city_name'].isna() | df['date'].isna()\n",
    "    if null_mask.any():\n",
    "        LOGGER.warning(f\"Dropping {null_mask.sum()} rows with NaNs in city_name or date.\")\n",
    "        df = df[~null_mask]\n",
    "\n",
    "    # Rename 'date' -> 'ds' for Prophet convenience\n",
    "    df.rename(columns={'date': 'ds'}, inplace=True)\n",
    "\n",
    "    # Sort by ds ascending\n",
    "    df.sort_values('ds', inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    LOGGER.info(\n",
    "        f\"Data loaded. Shape: {df.shape}, Unique cities: {df['city_name'].nunique()}\"\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# MODELING & HELPER FUNCTIONS (Mostly same as before)\n",
    "# ------------------------------------------------------------------------\n",
    "def tune_prophet_hyperparams(df: pd.DataFrame, param_grid: dict, initial: str, period: str, horizon: str) -> Prophet:\n",
    "    LOGGER.info(\"Tuning Prophet hyperparameters ...\")\n",
    "    best_model = None\n",
    "    best_rmse = float('inf')\n",
    "    \n",
    "    for cps in param_grid[\"changepoint_prior_scale\"]:\n",
    "        for mode in param_grid[\"seasonality_mode\"]:\n",
    "            temp_model = Prophet(\n",
    "                yearly_seasonality=True,\n",
    "                weekly_seasonality=True,\n",
    "                seasonality_mode=mode,\n",
    "                changepoint_prior_scale=cps\n",
    "            )\n",
    "            temp_model.fit(df[['ds', 'y']])\n",
    "            \n",
    "            try:\n",
    "                df_cv = cross_validation(temp_model, initial=initial, period=period, horizon=horizon)\n",
    "                metrics = performance_metrics(df_cv)\n",
    "                rmse = metrics['rmse'].mean()\n",
    "            except Exception as e:\n",
    "                LOGGER.warning(\n",
    "                    f\"[Prophet CV] Failed for CPS={cps}, Mode={mode}, error={e}. \"\n",
    "                    \"Assigning large RMSE=9999999 to this combination.\"\n",
    "                )\n",
    "                rmse = 9999999\n",
    "            \n",
    "            LOGGER.info(f\"Hyperparams => CPS={cps}, Mode={mode}, Mean RMSE={rmse:.3f}\")\n",
    "            if rmse < best_rmse:\n",
    "                best_rmse = rmse\n",
    "                best_model = temp_model\n",
    "    \n",
    "    if best_model is None:\n",
    "        LOGGER.warning(\"All cross validation attempts failed; using default Prophet model.\")\n",
    "        best_model = Prophet().fit(df[['ds','y']])\n",
    "    \n",
    "    LOGGER.info(f\"Best Prophet hyperparams => RMSE={best_rmse:.3f}\")\n",
    "    return best_model\n",
    "\n",
    "def prophet_cross_val_evaluation(model, initial, period, horizon):\n",
    "    LOGGER.info(\"Running Prophet cross-validation ...\")\n",
    "    try:\n",
    "        df_cv = cross_validation(model, initial=initial, period=period, horizon=horizon)\n",
    "        df_metrics = performance_metrics(df_cv)\n",
    "        LOGGER.info(f\"Prophet CV metrics:\\n{df_metrics.head()}\")\n",
    "        return df_cv, df_metrics\n",
    "    except Exception as e:\n",
    "        LOGGER.warning(f\"Prophet cross-validation failed: {e}\")\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "def build_residual_dataset(df: pd.DataFrame, prophet_model: Prophet) -> pd.DataFrame:\n",
    "    LOGGER.info(\"Creating in-sample forecast to compute residuals ...\")\n",
    "    # Predict only the historical range\n",
    "    in_sample = prophet_model.make_future_dataframe(periods=0)\n",
    "    forecast = prophet_model.predict(in_sample)\n",
    "    df_merged = pd.merge(df, forecast[['ds','yhat']], on='ds', how='left')\n",
    "    df_merged['residual'] = df_merged['y'] - df_merged['yhat']\n",
    "    return df_merged\n",
    "\n",
    "def create_lag_features(df_res: pd.DataFrame, target_col='residual', max_lag=3) -> pd.DataFrame:\n",
    "    LOGGER.info(\"Creating lag features for the residual ...\")\n",
    "    df_lag = df_res.copy()\n",
    "    df_lag['day_of_year'] = df_lag['ds'].dt.dayofyear\n",
    "    df_lag['day_of_week'] = df_lag['ds'].dt.dayofweek\n",
    "    for lag in range(1, max_lag+1):\n",
    "        df_lag[f'{target_col}_lag_{lag}'] = df_lag[target_col].shift(lag)\n",
    "    df_lag.dropna(inplace=True)\n",
    "    return df_lag\n",
    "\n",
    "def evaluate_model_predictions(y_true, y_pred, model_name=\"Model\"):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    if np.all(y_true != 0):\n",
    "        mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    else:\n",
    "        mape = np.nan\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    LOGGER.info(\n",
    "        f\"{model_name} => MAE={mae:.3f}, RMSE={rmse:.3f}, MAPE={mape:.2f}%, R^2={r2:.3f}\"\n",
    "    )\n",
    "    return {\"mae\": mae, \"rmse\": rmse, \"mape\": mape, \"r2\": r2}\n",
    "\n",
    "def tune_residual_model(df_supervised: pd.DataFrame, param_dist: dict, n_iter: int,\n",
    "                        cv_splits: int, random_state: int, target_col='residual'):\n",
    "    LOGGER.info(\"Training RandomForest on residual with RandomizedSearchCV ...\")\n",
    "    feature_cols = [c for c in df_supervised.columns if 'lag_' in c or 'day_of_' in c]\n",
    "    X = df_supervised[feature_cols]\n",
    "    y = df_supervised[target_col]\n",
    "    \n",
    "    tscv = TimeSeriesSplit(n_splits=cv_splits)\n",
    "    rf = RandomForestRegressor(random_state=random_state)\n",
    "    \n",
    "    randomized_search = RandomizedSearchCV(\n",
    "        estimator=rf,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=n_iter,\n",
    "        cv=tscv,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        random_state=random_state,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    randomized_search.fit(X, y)\n",
    "    \n",
    "    best_rf_model = randomized_search.best_estimator_\n",
    "    best_params = randomized_search.best_params_\n",
    "    best_score = -randomized_search.best_score_\n",
    "    LOGGER.info(f\"Best RF Params => {best_params}, MSE={best_score:.2f}\")\n",
    "    \n",
    "    y_pred = best_rf_model.predict(X)\n",
    "    _ = evaluate_model_predictions(y, y_pred, model_name=\"RandomForest (Residual)\")\n",
    "    \n",
    "    return best_rf_model, feature_cols\n",
    "\n",
    "def iterative_residual_prediction(model, df_history, future_dates, feature_cols, max_lag=3) -> pd.DataFrame:\n",
    "    df_temp = df_history.copy()\n",
    "    predictions = []\n",
    "    for dt in future_dates:\n",
    "        last_row = df_temp.iloc[-1].copy()\n",
    "        # Shift residual forward\n",
    "        for lag in range(1, max_lag+1):\n",
    "            if lag == 1:\n",
    "                val = last_row['residual']\n",
    "            else:\n",
    "                val = last_row[f'residual_lag_{lag-1}']\n",
    "            last_row[f'residual_lag_{lag}'] = val\n",
    "        \n",
    "        last_row['ds'] = dt\n",
    "        last_row['day_of_year'] = dt.day_of_year\n",
    "        last_row['day_of_week'] = dt.day_of_week\n",
    "        \n",
    "        X_new = pd.DataFrame([last_row[feature_cols]], columns=feature_cols)\n",
    "        resid_pred = model.predict(X_new)[0]\n",
    "        \n",
    "        new_row = last_row.copy()\n",
    "        new_row['ds'] = dt\n",
    "        new_row['residual'] = resid_pred\n",
    "        predictions.append([dt, resid_pred])\n",
    "        \n",
    "        df_temp = pd.concat([df_temp, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    \n",
    "    df_pred = pd.DataFrame(predictions, columns=['ds','residual_pred'])\n",
    "    return df_pred\n",
    "\n",
    "def create_hybrid_forecast(prophet_model, rf_model, df_supervised, feature_cols, target_year, max_lag):\n",
    "    LOGGER.info(f\"Creating hybrid forecast for {target_year} ...\")\n",
    "    start_date = f\"{target_year}-01-01\"\n",
    "    end_date = f\"{target_year}-12-31\"\n",
    "    last_ds = df_supervised['ds'].max()\n",
    "    days_needed = (pd.to_datetime(end_date) - last_ds).days\n",
    "    if days_needed < 1:\n",
    "        raise ValueError(f\"Requested year {target_year} <= last training date {last_ds}.\")\n",
    "\n",
    "    # Prophet forecast\n",
    "    future_df = prophet_model.make_future_dataframe(periods=days_needed)\n",
    "    prophet_forecast = prophet_model.predict(future_df)\n",
    "    prophet_future = prophet_forecast[\n",
    "        (prophet_forecast['ds'] >= start_date) & (prophet_forecast['ds'] <= end_date)\n",
    "    ].copy()\n",
    "\n",
    "    # Residual forecast\n",
    "    df_history_for_res = df_supervised.iloc[[-1]].copy()\n",
    "    future_dates = pd.to_datetime(prophet_future['ds'].unique())\n",
    "    df_future_resid = iterative_residual_prediction(\n",
    "        rf_model, df_history_for_res, future_dates, feature_cols, max_lag\n",
    "    )\n",
    "\n",
    "    # Merge\n",
    "    hybrid_df = prophet_future.merge(df_future_resid, on='ds', how='left')\n",
    "    hybrid_df['residual_pred'].fillna(0, inplace=True)\n",
    "    hybrid_df['yhat_hybrid'] = hybrid_df['yhat'] + hybrid_df['residual_pred']\n",
    "    return hybrid_df\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# PLOTTING FUNCTION (Slightly generalized)\n",
    "# ------------------------------------------------------------------------\n",
    "def plot_full_forecast_and_save(city: str, forecast_df: pd.DataFrame, target_year: int, var_name: str):\n",
    "    \"\"\"\n",
    "    Plots the forecast for the given 'var_name' (e.g., 'mean', 'max', or 'min').\n",
    "    We show:\n",
    "      - Observed history (black)\n",
    "      - Prophet baseline (blue dashed)\n",
    "      - Hybrid forecast (red)\n",
    "      - Monthly average bar of the hybrid forecast\n",
    "    \"\"\"\n",
    "    LOGGER.info(f\"Plotting {var_name} forecast for city={city}, year={target_year}\")\n",
    "    # Load full data to get historical \"y\"\n",
    "    df_all = load_data_multi_city(CONFIG[\"csv_path\"])\n",
    "    df_city = df_all[df_all[\"city_name\"] == city].copy()\n",
    "    if df_city.empty:\n",
    "        LOGGER.warning(f\"No historical data found for city: {city}\")\n",
    "        return\n",
    "\n",
    "    # We assume the user replaced the actual data with 'y' for training, \n",
    "    # so let's do the same here for consistency in plotting:\n",
    "    # We'll do that if you stored 'y' in the same column. Otherwise, \n",
    "    # you'd store the actual col differently. For minimal changes, let's do a fallback:\n",
    "    # For \"mean\" -> use \"temperature_2m_mean (°C)\"\n",
    "    # For \"max\"  -> use \"temperature_2m_max (°C)\"\n",
    "    # For \"min\"  -> use \"temperature_2m_min (°C)\"\n",
    "    # You can adapt as needed if your actual data differs.\n",
    "\n",
    "    # Convert ds to datetime\n",
    "    if not pd.api.types.is_datetime64_any_dtype(forecast_df['ds']):\n",
    "        forecast_df['ds'] = pd.to_datetime(forecast_df['ds'])\n",
    "    \n",
    "    # Filter for the target year\n",
    "    forecast_year = forecast_df[forecast_df['ds'].dt.year == target_year].copy()\n",
    "    if forecast_year.empty:\n",
    "        LOGGER.warning(f\"No forecast data found for {var_name} in {target_year}.\")\n",
    "        return\n",
    "\n",
    "    forecast_start = forecast_year['ds'].min()\n",
    "    observed = df_city[df_city['ds'] < forecast_start].copy()\n",
    "\n",
    "    # If you want to plot the actual historical col, do something like:\n",
    "    if var_name == \"mean\":\n",
    "        if \"temperature_2m_mean (°C)\" in observed.columns:\n",
    "            observed.rename(columns={\"temperature_2m_mean (°C)\": \"y\"}, inplace=True)\n",
    "        else:\n",
    "            observed[\"y\"] = np.nan\n",
    "    elif var_name == \"max\":\n",
    "        if \"temperature_2m_max (°C)\" in observed.columns:\n",
    "            observed.rename(columns={\"temperature_2m_max (°C)\": \"y\"}, inplace=True)\n",
    "        else:\n",
    "            observed[\"y\"] = np.nan\n",
    "    elif var_name == \"min\":\n",
    "        if \"temperature_2m_min (°C)\" in observed.columns:\n",
    "            observed.rename(columns={\"temperature_2m_min (°C)\": \"y\"}, inplace=True)\n",
    "        else:\n",
    "            observed[\"y\"] = np.nan\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "    # --- Top subplot ---\n",
    "    ax1 = axes[0]\n",
    "    ax1.set_title(f\"Hybrid {var_name.title()} Temperature Forecast for {city} ({target_year})\")\n",
    "\n",
    "    # Observed (black)\n",
    "    ax1.plot(observed['ds'], observed['y'], color='black', label='Observed (History)')\n",
    "\n",
    "    # Prophet baseline (blue dashed)\n",
    "    if 'yhat_lower' in forecast_year.columns and 'yhat_upper' in forecast_year.columns:\n",
    "        ax1.fill_between(\n",
    "            forecast_year['ds'],\n",
    "            forecast_year['yhat_lower'],\n",
    "            forecast_year['yhat_upper'],\n",
    "            color='gray', alpha=0.2,\n",
    "            label='Prophet Uncertainty'\n",
    "        )\n",
    "    ax1.plot(\n",
    "        forecast_year['ds'],\n",
    "        forecast_year['yhat'],\n",
    "        linestyle='--',\n",
    "        color='blue',\n",
    "        label='Prophet Baseline'\n",
    "    )\n",
    "\n",
    "    # Hybrid (red)\n",
    "    ax1.plot(\n",
    "        forecast_year['ds'],\n",
    "        forecast_year['yhat_hybrid'],\n",
    "        color='red',\n",
    "        label='Hybrid Forecast'\n",
    "    )\n",
    "\n",
    "    ax1.set_ylabel(f\"{var_name.title()} Temp (°C)\")\n",
    "    ax1.legend(loc='best')\n",
    "\n",
    "    # --- Bottom subplot: monthly average of the hybrid forecast\n",
    "    ax2 = axes[1]\n",
    "    ax2.set_title(f\"Monthly Average {var_name.title()} Temperature ({target_year})\")\n",
    "    forecast_year['month'] = forecast_year['ds'].dt.month\n",
    "    monthly_avg = (\n",
    "        forecast_year.groupby('month')['yhat_hybrid']\n",
    "        .mean()\n",
    "        .reset_index(name='avg_temp')\n",
    "    )\n",
    "    ax2.bar(monthly_avg['month'], monthly_avg['avg_temp'])\n",
    "    ax2.set_xlabel(\"Month\")\n",
    "    ax2.set_ylabel(f\"Avg {var_name.title()} Temp (°C)\")\n",
    "    ax2.set_xticks(range(1,13))\n",
    "    ax2.set_xticklabels([f\"{m:02d}\" for m in range(1,13)])\n",
    "    ax2.set_xlim([0.5,12.5])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plot_filename = os.path.join(\n",
    "        CONFIG[\"output_dir\"],\n",
    "        f\"{city}_{var_name}_forecast_{target_year}_hybrid.png\"\n",
    "    )\n",
    "    plt.savefig(plot_filename, dpi=150)\n",
    "    LOGGER.info(f\"Chart saved to {plot_filename}\")\n",
    "    plt.show()\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# TRAINING LOOP FOR ALL CITIES & 3 COLUMNS\n",
    "# ------------------------------------------------------------------------\n",
    "df_all = load_data_multi_city(CONFIG[\"csv_path\"])\n",
    "unique_cities = df_all['city_name'].unique()\n",
    "LOGGER.info(f\"Found {len(unique_cities)} cities: {unique_cities}\")\n",
    "\n",
    "for city in unique_cities:\n",
    "    df_city = df_all[df_all['city_name'] == city].copy()\n",
    "    LOGGER.info(f\"\\n===== Processing city: {city} | Data shape: {df_city.shape} =====\")\n",
    "    \n",
    "    # If the city has fewer than 2 rows, skip\n",
    "    if df_city.shape[0] < 2:\n",
    "        LOGGER.warning(f\"Not enough data for city {city}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # For each of the three columns (mean, max, min), do the same pipeline\n",
    "    for temp_col in CONFIG[\"temp_columns\"]:\n",
    "        LOGGER.info(f\"\\n--- Forecasting column '{temp_col}' for city={city} ---\")\n",
    "\n",
    "        # 1) Rename that column to 'y'\n",
    "        if temp_col not in df_city.columns:\n",
    "            LOGGER.warning(f\"Column '{temp_col}' not found for city={city}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        df_for_prophet = df_city[['ds', temp_col]].copy()\n",
    "        df_for_prophet.rename(columns={temp_col: 'y'}, inplace=True)\n",
    "\n",
    "        # Drop rows with missing y\n",
    "        df_for_prophet.dropna(subset=['y'], inplace=True)\n",
    "        if df_for_prophet.shape[0] < 2:\n",
    "            LOGGER.warning(f\"Not enough valid rows in '{temp_col}' for city={city}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # 2) Train Prophet\n",
    "        prophet_model = tune_prophet_hyperparams(\n",
    "            df_for_prophet,\n",
    "            CONFIG[\"prophet_param_grid\"],\n",
    "            CONFIG[\"initial\"],\n",
    "            CONFIG[\"period\"],\n",
    "            CONFIG[\"horizon\"]\n",
    "        )\n",
    "\n",
    "        # Optional cross validation\n",
    "        _, _ = prophet_cross_val_evaluation(\n",
    "            prophet_model,\n",
    "            CONFIG[\"initial\"],\n",
    "            CONFIG[\"period\"],\n",
    "            CONFIG[\"horizon\"]\n",
    "        )\n",
    "\n",
    "        # 3) Build residual dataset\n",
    "        df_residual = build_residual_dataset(df_for_prophet, prophet_model)\n",
    "        df_supervised = create_lag_features(df_residual, target_col='residual', max_lag=CONFIG[\"max_lag\"])\n",
    "        if df_supervised.empty:\n",
    "            LOGGER.warning(f\"Residual dataset empty after lagging for {temp_col} in city={city}.\")\n",
    "            continue\n",
    "\n",
    "        # 4) RandomForest on residual\n",
    "        rf_model, feature_cols = tune_residual_model(\n",
    "            df_supervised,\n",
    "            CONFIG[\"rf_param_dist\"],\n",
    "            CONFIG[\"n_iter_rf_random_search\"],\n",
    "            CONFIG[\"cv_splits\"],\n",
    "            CONFIG[\"random_state\"]\n",
    "        )\n",
    "\n",
    "        # 5) Hybrid forecast\n",
    "        target_year = CONFIG[\"target_year\"]\n",
    "        try:\n",
    "            hybrid_forecast = create_hybrid_forecast(\n",
    "                prophet_model,\n",
    "                rf_model,\n",
    "                df_supervised,\n",
    "                feature_cols,\n",
    "                target_year,\n",
    "                CONFIG[\"max_lag\"]\n",
    "            )\n",
    "        except ValueError as e:\n",
    "            LOGGER.warning(f\"Could not create forecast for city={city}, col={temp_col}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # 6) Plot & save\n",
    "        # We pick a label for the variable (like 'mean','max','min')\n",
    "        if \"mean\" in temp_col.lower():\n",
    "            var_name = \"mean\"\n",
    "        elif \"max\" in temp_col.lower():\n",
    "            var_name = \"max\"\n",
    "        elif \"min\" in temp_col.lower():\n",
    "            var_name = \"min\"\n",
    "        else:\n",
    "            var_name = \"temp\"\n",
    "\n",
    "        plot_full_forecast_and_save(city, hybrid_forecast, target_year, var_name)\n",
    "\n",
    "        # Save the forecast CSV\n",
    "        safe_col_name = temp_col.replace(\" \",\"_\").replace(\"(\",\"\").replace(\")\",\"\")\n",
    "        forecast_filename = os.path.join(\n",
    "            CONFIG[\"output_dir\"],\n",
    "            f\"{city}_{safe_col_name}_{target_year}_hybrid.csv\"\n",
    "        )\n",
    "        hybrid_forecast.to_csv(forecast_filename, index=False)\n",
    "        LOGGER.info(f\"Forecast for {temp_col} saved to {forecast_filename}\")\n",
    "\n",
    "        # 7) Save the models\n",
    "        model_prefix = safe_col_name  # e.g. \"temperature_2m_mean_°C\"\n",
    "        prophet_path = os.path.join(CONFIG[\"model_dir\"], f\"{city}_prophet_{model_prefix}.pkl\")\n",
    "        rf_path = os.path.join(CONFIG[\"model_dir\"], f\"{city}_rf_residual_{model_prefix}.pkl\")\n",
    "\n",
    "        joblib.dump(prophet_model, prophet_path)\n",
    "        joblib.dump(rf_model, rf_path)\n",
    "        LOGGER.info(f\"Saved Prophet model to {prophet_path}\")\n",
    "        LOGGER.info(f\"Saved RF model to {rf_path}\")\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# PREDICTION FUNCTION (Slightly adapted for multiple columns)\n",
    "# ------------------------------------------------------------------------\n",
    "def predict_forecast(city: str, target_year: int, temp_col: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads saved Prophet + RF models (specific to 'temp_col') for the city,\n",
    "    rebuilds the residual dataset, and produces the hybrid forecast for target_year.\n",
    "    \"\"\"\n",
    "    df_all = load_data_multi_city(CONFIG[\"csv_path\"])\n",
    "    df_city = df_all[df_all[\"city_name\"] == city].copy()\n",
    "    if df_city.shape[0] < 2:\n",
    "        raise ValueError(f\"Not enough data for city='{city}'\")\n",
    "\n",
    "    # Convert the chosen column -> 'y'\n",
    "    if temp_col not in df_city.columns:\n",
    "        raise ValueError(f\"Column '{temp_col}' not found for city='{city}' in data.\")\n",
    "\n",
    "    df_for_prophet = df_city[['ds', temp_col]].copy()\n",
    "    df_for_prophet.rename(columns={temp_col: 'y'}, inplace=True)\n",
    "    df_for_prophet.dropna(subset=['y'], inplace=True)\n",
    "    if df_for_prophet.shape[0] < 2:\n",
    "        raise ValueError(f\"No valid data in '{temp_col}' for city='{city}'.\")\n",
    "\n",
    "    # Load the correct models\n",
    "    safe_col_name = temp_col.replace(\" \",\"_\").replace(\"(\",\"\").replace(\")\",\"\")\n",
    "    prophet_path = os.path.join(CONFIG[\"model_dir\"], f\"{city}_prophet_{safe_col_name}.pkl\")\n",
    "    rf_path = os.path.join(CONFIG[\"model_dir\"], f\"{city}_rf_residual_{safe_col_name}.pkl\")\n",
    "\n",
    "    if not os.path.exists(prophet_path) or not os.path.exists(rf_path):\n",
    "        raise FileNotFoundError(f\"Model files for {temp_col} in city='{city}' not found.\")\n",
    "\n",
    "    prophet_model = joblib.load(prophet_path)\n",
    "    rf_model = joblib.load(rf_path)\n",
    "\n",
    "    # Rebuild residual dataset\n",
    "    df_residual = build_residual_dataset(df_for_prophet, prophet_model)\n",
    "    df_supervised = create_lag_features(df_residual, target_col='residual', max_lag=CONFIG[\"max_lag\"])\n",
    "    if df_supervised.empty:\n",
    "        raise ValueError(f\"No valid residual data after lagging for city='{city}' & col='{temp_col}'.\")\n",
    "\n",
    "    feature_cols = [c for c in df_supervised.columns if 'lag_' in c or 'day_of_' in c]\n",
    "\n",
    "    # Hybrid forecast\n",
    "    forecast = create_hybrid_forecast(\n",
    "        prophet_model,\n",
    "        rf_model,\n",
    "        df_supervised,\n",
    "        feature_cols,\n",
    "        target_year,\n",
    "        CONFIG[\"max_lag\"]\n",
    "    )\n",
    "    return forecast\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

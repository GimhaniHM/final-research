{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import joblib\n",
    "import logging\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# LOGGING & CONFIGURATION\n",
    "# ------------------------------------------------------------------------\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "\n",
    "CONFIG = {\n",
    "    \"csv_path\": \"/kaggle/input/new-city-base-data/city_base_weather.csv\",  # Update if needed\n",
    "    \"output_dir\": \"forecasts\",\n",
    "    \"model_dir\": \"models\",\n",
    "    \"initial\": \"365 days\",\n",
    "    \"period\": \"180 days\",\n",
    "    \"horizon\": \"90 days\",\n",
    "    \"max_lag\": 3,\n",
    "    \"prophet_param_grid\": {\n",
    "        \"changepoint_prior_scale\": [0.05, 0.1, 0.2],\n",
    "        \"seasonality_mode\": [\"additive\", \"multiplicative\"]\n",
    "    },\n",
    "    \"rf_param_dist\": {\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"max_depth\": [3, 5, 7, 10, None],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"max_features\": [\"sqrt\", \"log2\", None]\n",
    "    },\n",
    "    \"n_iter_rf_random_search\": 10,\n",
    "    \"cv_splits\": 3,\n",
    "    \"random_state\": 42,\n",
    "    # Used in the training loop below\n",
    "    \"target_year\": 2026  \n",
    "}\n",
    "\n",
    "os.makedirs(CONFIG[\"model_dir\"], exist_ok=True)\n",
    "os.makedirs(CONFIG[\"output_dir\"], exist_ok=True)\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# DATA LOADING FUNCTION\n",
    "# ------------------------------------------------------------------------\n",
    "def load_data_multi_city(csv_path: str) -> pd.DataFrame:\n",
    "    LOGGER.info(f\"Loading data from {csv_path} ...\")\n",
    "    \n",
    "    if not os.path.isfile(csv_path):\n",
    "        raise FileNotFoundError(f\"Could not find file: {csv_path}\")\n",
    "    \n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Check for required columns\n",
    "    required_cols = ['city_name', 'date', 'rain_sum (mm)']\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"CSV missing columns: {missing_cols}\")\n",
    "\n",
    "    # Rename columns to match Prophet expectations\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "    df.rename(columns={'date': 'ds', 'rain_sum (mm)': 'y'}, inplace=True)\n",
    "    df.sort_values('ds', inplace=True)\n",
    "\n",
    "    # Drop rows with missing ds or y\n",
    "    null_mask = df['ds'].isna() | df['y'].isna()\n",
    "    if null_mask.any():\n",
    "        LOGGER.warning(f\"Dropping {null_mask.sum()} rows with NaNs in ds or y.\")\n",
    "        df = df[~null_mask]\n",
    "\n",
    "    # Clip extreme outliers (optional, helps robust training)\n",
    "    df['y'] = df['y'].clip(lower=0, upper=df['y'].quantile(0.999))\n",
    "    \n",
    "    LOGGER.info(f\"Data loaded. Shape: {df.shape}, Unique cities: {df['city_name'].nunique()}\")\n",
    "    return df\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# MODEL FUNCTIONS\n",
    "# ------------------------------------------------------------------------\n",
    "def tune_prophet_hyperparams(df: pd.DataFrame, param_grid: dict, initial: str, period: str, horizon: str) -> Prophet:\n",
    "    \"\"\"\n",
    "    Tries each combination of changepoint_prior_scale and seasonality_mode. \n",
    "    Uses cross_validation to compute RMSE. If cross_validation fails (likely \n",
    "    because the data is too short), it logs a warning and assigns a large RMSE \n",
    "    to that combination. Returns the model (and hyperparams) with the lowest RMSE.\n",
    "    \"\"\"\n",
    "    LOGGER.info(\"Tuning Prophet hyperparameters ...\")\n",
    "    best_model = None\n",
    "    best_rmse = float('inf')\n",
    "    \n",
    "    for cps in param_grid[\"changepoint_prior_scale\"]:\n",
    "        for mode in param_grid[\"seasonality_mode\"]:\n",
    "            temp_model = Prophet(\n",
    "                yearly_seasonality=True,\n",
    "                weekly_seasonality=True,\n",
    "                seasonality_mode=mode,\n",
    "                changepoint_prior_scale=cps\n",
    "            )\n",
    "            \n",
    "            # Fit on entire data (Prophet requires at least 2 data points)\n",
    "            temp_model.fit(df[['ds', 'y']])\n",
    "            \n",
    "            # Attempt cross validation\n",
    "            try:\n",
    "                df_cv = cross_validation(temp_model, initial=initial, period=period, horizon=horizon)\n",
    "                metrics = performance_metrics(df_cv)\n",
    "                rmse = metrics['rmse'].mean()\n",
    "            except Exception as e:\n",
    "                LOGGER.warning(\n",
    "                    f\"[Prophet CV] Failed for CPS={cps}, Mode={mode}, error: {str(e)}. \"\n",
    "                    \"Assigning large RMSE=9999999 to this combination.\"\n",
    "                )\n",
    "                rmse = 9999999\n",
    "            \n",
    "            LOGGER.info(f\"Hyperparams => CPS={cps}, Mode={mode}, Mean RMSE={rmse:.3f}\")\n",
    "            if rmse < best_rmse:\n",
    "                best_rmse = rmse\n",
    "                best_model = temp_model\n",
    "    \n",
    "    if best_model is None:\n",
    "        # Fallback: in case *all* combos fail, just fit a default with no CV\n",
    "        LOGGER.warning(\"All cross validation attempts failed; using default Prophet model.\")\n",
    "        best_model = Prophet().fit(df[['ds', 'y']])\n",
    "    \n",
    "    LOGGER.info(f\"Best Prophet hyperparams => RMSE={best_rmse:.3f}\")\n",
    "    return best_model\n",
    "\n",
    "def prophet_cross_val_evaluation(model, initial, period, horizon):\n",
    "    \"\"\"\n",
    "    A separate cross validation step if you want to log performance metrics.\n",
    "    If cross validation fails, it will log a warning and return empty DataFrames.\n",
    "    \"\"\"\n",
    "    LOGGER.info(\"Running Prophet cross-validation ...\")\n",
    "    try:\n",
    "        df_cv = cross_validation(model, initial=initial, period=period, horizon=horizon)\n",
    "        df_metrics = performance_metrics(df_cv)\n",
    "        LOGGER.info(f\"Prophet CV metrics:\\n{df_metrics.head()}\")\n",
    "        return df_cv, df_metrics\n",
    "    except Exception as e:\n",
    "        LOGGER.warning(f\"Prophet cross-validation failed: {str(e)}\")\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "def build_residual_dataset(df: pd.DataFrame, prophet_model: Prophet) -> pd.DataFrame:\n",
    "    LOGGER.info(\"Creating in-sample forecast to compute residuals ...\")\n",
    "    in_sample_future = prophet_model.make_future_dataframe(periods=0)\n",
    "    forecast = prophet_model.predict(in_sample_future)\n",
    "    df_merged = pd.merge(df, forecast[['ds', 'yhat']], on='ds', how='left')\n",
    "    df_merged['residual'] = df_merged['y'] - df_merged['yhat']\n",
    "    return df_merged\n",
    "\n",
    "def create_lag_features(df_res: pd.DataFrame, target_col='residual', max_lag=3) -> pd.DataFrame:\n",
    "    LOGGER.info(\"Creating lag features for the residual ...\")\n",
    "    df_lag = df_res.copy()\n",
    "    df_lag['day_of_year'] = df_lag['ds'].dt.dayofyear\n",
    "    df_lag['day_of_week'] = df_lag['ds'].dt.dayofweek\n",
    "    for lag in range(1, max_lag + 1):\n",
    "        df_lag[f'{target_col}_lag_{lag}'] = df_lag[target_col].shift(lag)\n",
    "    df_lag.dropna(inplace=True)\n",
    "    return df_lag\n",
    "\n",
    "def evaluate_model_predictions(y_true, y_pred, model_name=\"Model\"):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    # Avoid division by zero in MAPE if y_true has zeros\n",
    "    if np.all(y_true != 0):\n",
    "        mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    else:\n",
    "        mape = np.nan\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    LOGGER.info(f\"{model_name} => MAE: {mae:.3f}, RMSE: {rmse:.3f}, MAPE: {mape:.2f}%, R^2: {r2:.3f}\")\n",
    "    return {\"mae\": mae, \"rmse\": rmse, \"mape\": mape, \"r2\": r2}\n",
    "\n",
    "def tune_residual_model(df_supervised: pd.DataFrame, param_dist: dict, n_iter: int, cv_splits: int, random_state: int, target_col='residual'):\n",
    "    LOGGER.info(\"Training RandomForest on residual with RandomizedSearchCV ...\")\n",
    "    feature_cols = [c for c in df_supervised.columns if 'lag_' in c or 'day_of_' in c]\n",
    "    X = df_supervised[feature_cols]\n",
    "    y = df_supervised[target_col]\n",
    "    \n",
    "    tscv = TimeSeriesSplit(n_splits=cv_splits)\n",
    "    rf = RandomForestRegressor(random_state=random_state)\n",
    "    randomized_search = RandomizedSearchCV(\n",
    "        estimator=rf,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=n_iter,\n",
    "        cv=tscv,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        random_state=random_state,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    randomized_search.fit(X, y)\n",
    "    \n",
    "    best_rf_model = randomized_search.best_estimator_\n",
    "    best_params = randomized_search.best_params_\n",
    "    best_score = -randomized_search.best_score_\n",
    "    LOGGER.info(f\"Best RF Params => {best_params}, MSE={best_score:.2f}\")\n",
    "    \n",
    "    y_pred = best_rf_model.predict(X)\n",
    "    _ = evaluate_model_predictions(y, y_pred, model_name=\"RandomForest (Residual)\")\n",
    "    \n",
    "    return best_rf_model, feature_cols\n",
    "\n",
    "def iterative_residual_prediction(model, df_history, future_dates, feature_cols, max_lag=3) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Step forward in time, using the newly predicted residual as a lag for the next day.\n",
    "    \"\"\"\n",
    "    df_temp = df_history.copy()\n",
    "    predictions = []\n",
    "    for dt in future_dates:\n",
    "        last_row = df_temp.iloc[-1].copy()\n",
    "        for lag in range(1, max_lag + 1):\n",
    "            if lag == 1:\n",
    "                new_lag_val = last_row['residual']\n",
    "            else:\n",
    "                new_lag_val = last_row[f'residual_lag_{lag - 1}']\n",
    "            last_row[f'residual_lag_{lag}'] = new_lag_val\n",
    "        \n",
    "        last_row['ds'] = dt\n",
    "        last_row['day_of_year'] = dt.day_of_year\n",
    "        last_row['day_of_week'] = dt.day_of_week\n",
    "        \n",
    "        X_new = pd.DataFrame([last_row[feature_cols]], columns=feature_cols)\n",
    "        resid_pred = model.predict(X_new)[0]\n",
    "        \n",
    "        new_row = last_row.copy()\n",
    "        new_row['ds'] = dt\n",
    "        new_row['residual'] = resid_pred\n",
    "        predictions.append([dt, resid_pred])\n",
    "        \n",
    "        df_temp = pd.concat([df_temp, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    \n",
    "    df_pred = pd.DataFrame(predictions, columns=['ds', 'residual_pred'])\n",
    "    return df_pred\n",
    "\n",
    "def create_hybrid_forecast(prophet_model, rf_model, df_supervised, feature_cols, target_year, max_lag):\n",
    "    LOGGER.info(f\"Creating hybrid forecast for {target_year} ...\")\n",
    "    start_date = f\"{target_year}-01-01\"\n",
    "    end_date = f\"{target_year}-12-31\"\n",
    "    last_training_date = df_supervised['ds'].max()\n",
    "    \n",
    "    days_needed = (pd.to_datetime(end_date) - last_training_date).days\n",
    "    if days_needed < 1:\n",
    "        raise ValueError(\n",
    "            f\"Requested year {target_year} is before/equal to \"\n",
    "            f\"the last training date {last_training_date}.\"\n",
    "        )\n",
    "    \n",
    "    # Prophet forecast for the required days\n",
    "    future_df = prophet_model.make_future_dataframe(periods=days_needed)\n",
    "    prophet_forecast = prophet_model.predict(future_df)\n",
    "    prophet_future = prophet_forecast[\n",
    "        (prophet_forecast['ds'] >= start_date) & (prophet_forecast['ds'] <= end_date)\n",
    "    ].copy()\n",
    "    \n",
    "    # Generate residual predictions iteratively\n",
    "    # Start from the last supervised (lag) row to propagate the lags properly\n",
    "    df_history_for_residual = df_supervised.iloc[[-1]].copy()\n",
    "    future_dates = pd.to_datetime(prophet_future['ds'].unique())\n",
    "    \n",
    "    df_future_resid = iterative_residual_prediction(\n",
    "        model=rf_model,\n",
    "        df_history=df_history_for_residual,\n",
    "        future_dates=future_dates,\n",
    "        feature_cols=feature_cols,\n",
    "        max_lag=max_lag\n",
    "    )\n",
    "    hybrid_df = prophet_future.merge(df_future_resid, on='ds', how='left')\n",
    "    \n",
    "    # If no residual_pred for some dates, fill them with 0\n",
    "    hybrid_df['residual_pred'].fillna(0, inplace=True)\n",
    "    \n",
    "    # Final hybrid forecast\n",
    "    hybrid_df['yhat_hybrid'] = hybrid_df['yhat'] + hybrid_df['residual_pred']\n",
    "    return hybrid_df\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# PLOTTING FUNCTION (2-SUBPLOT STYLE)\n",
    "# ------------------------------------------------------------------------\n",
    "def plot_full_forecast_and_save(city: str, forecast_df: pd.DataFrame, target_year: int):\n",
    "    \"\"\"\n",
    "    Plots the two‐subplot forecast chart and saves it as a PNG:\n",
    "      - Top subplot: Observed history (black), Prophet forecast (blue w/ uncertainty), Hybrid forecast (red).\n",
    "      - Bottom subplot: Monthly average of the Hybrid forecast (bar chart).\n",
    "    \"\"\"\n",
    "    LOGGER.info(f\"Plotting forecast for city={city}, year={target_year}\")\n",
    "    df_all = load_data_multi_city(CONFIG[\"csv_path\"])\n",
    "    df_city = df_all[df_all[\"city_name\"] == city].copy()\n",
    "    if df_city.empty:\n",
    "        LOGGER.warning(f\"No historical data found for city: {city}\")\n",
    "        return\n",
    "\n",
    "    # Ensure ds is datetime\n",
    "    if not pd.api.types.is_datetime64_any_dtype(forecast_df['ds']):\n",
    "        forecast_df['ds'] = pd.to_datetime(forecast_df['ds'])\n",
    "    \n",
    "    # Filter for the target year\n",
    "    forecast_year = forecast_df[forecast_df['ds'].dt.year == target_year].copy()\n",
    "    if forecast_year.empty:\n",
    "        LOGGER.warning(f\"No forecast data found for year {target_year} in {city}.\")\n",
    "        return\n",
    "\n",
    "    # Observed data up to the forecast start\n",
    "    forecast_start = forecast_year['ds'].min()\n",
    "    observed = df_city[df_city['ds'] < forecast_start]\n",
    "\n",
    "    # Create the figure with 2 subplots\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "    # --- Top subplot ---\n",
    "    ax1 = axes[0]\n",
    "    ax1.set_title(f\"Hybrid Rainfall Forecast for {city} ({target_year})\")\n",
    "\n",
    "    # Plot observed (black)\n",
    "    ax1.plot(observed['ds'], observed['y'], color='black', label='Observed (History)')\n",
    "\n",
    "    # Uncertainty band if columns exist\n",
    "    if 'yhat_lower' in forecast_year.columns and 'yhat_upper' in forecast_year.columns:\n",
    "        ax1.fill_between(\n",
    "            forecast_year['ds'],\n",
    "            forecast_year['yhat_lower'],\n",
    "            forecast_year['yhat_upper'],\n",
    "            color='gray',\n",
    "            alpha=0.2,\n",
    "            label='Prophet Uncertainty'\n",
    "        )\n",
    "\n",
    "    # Prophet Forecast (blue dashed)\n",
    "    if 'yhat' in forecast_year.columns:\n",
    "        ax1.plot(\n",
    "            forecast_year['ds'], \n",
    "            forecast_year['yhat'], \n",
    "            linestyle='--',\n",
    "            color='blue', \n",
    "            label='Prophet Baseline'\n",
    "        )\n",
    "\n",
    "    # Hybrid Forecast (red)\n",
    "    if 'yhat_hybrid' in forecast_year.columns:\n",
    "        ax1.plot(\n",
    "            forecast_year['ds'], \n",
    "            forecast_year['yhat_hybrid'], \n",
    "            color='red', \n",
    "            label='Hybrid Forecast'\n",
    "        )\n",
    "\n",
    "    ax1.set_ylabel(\"Rainfall (mm)\")\n",
    "    ax1.legend(loc='best')\n",
    "\n",
    "    # --- Bottom subplot ---\n",
    "    ax2 = axes[1]\n",
    "    ax2.set_title(f\"Monthly Average Hybrid Forecast ({target_year})\")\n",
    "\n",
    "    forecast_year['month'] = forecast_year['ds'].dt.month\n",
    "    monthly_avg = (\n",
    "        forecast_year.groupby('month')['yhat_hybrid']\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .rename(columns={'yhat_hybrid': 'avg_forecast'})\n",
    "    )\n",
    "\n",
    "    ax2.bar(monthly_avg['month'], monthly_avg['avg_forecast'])\n",
    "    ax2.set_xlabel(\"Month\")\n",
    "    ax2.set_ylabel(\"Avg Rainfall (mm)\")\n",
    "    ax2.set_xticks(range(1, 13))\n",
    "    ax2.set_xticklabels([f\"{m:02d}\" for m in range(1, 13)])\n",
    "    ax2.set_xlim([0.5, 12.5])\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the figure\n",
    "    plot_filename = os.path.join(CONFIG[\"output_dir\"], f\"{city}_hybrid_forecast_{target_year}.png\")\n",
    "    plt.savefig(plot_filename, dpi=150)\n",
    "    LOGGER.info(f\"Chart saved to {plot_filename}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# TRAINING LOOP FOR ALL CITIES (Runs Sequentially)\n",
    "# ------------------------------------------------------------------------\n",
    "df_all = load_data_multi_city(CONFIG[\"csv_path\"])\n",
    "unique_cities = df_all['city_name'].unique()\n",
    "LOGGER.info(f\"Found {len(unique_cities)} cities: {unique_cities}\")\n",
    "\n",
    "for city in unique_cities:\n",
    "    df_city = df_all[df_all[\"city_name\"] == city].copy()\n",
    "    LOGGER.info(f\"\\n===== Processing city: {city} | Data shape: {df_city.shape} =====\")\n",
    "    \n",
    "    # If the city has fewer than 2 rows, skip it (Prophet cannot train on 1 row)\n",
    "    if df_city.shape[0] < 2:\n",
    "        LOGGER.warning(f\"Not enough data for city {city}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # 1) Train Prophet model with hyperparameter tuning\n",
    "    prophet_model = tune_prophet_hyperparams(\n",
    "        df=df_city,\n",
    "        param_grid=CONFIG[\"prophet_param_grid\"],\n",
    "        initial=CONFIG[\"initial\"],\n",
    "        period=CONFIG[\"period\"],\n",
    "        horizon=CONFIG[\"horizon\"]\n",
    "    )\n",
    "    # Attempt a cross val evaluation (separate step, but if it fails, no big deal)\n",
    "    _, _ = prophet_cross_val_evaluation(\n",
    "        prophet_model,\n",
    "        CONFIG[\"initial\"],\n",
    "        CONFIG[\"period\"],\n",
    "        CONFIG[\"horizon\"]\n",
    "    )\n",
    "\n",
    "    # 2) Build residual dataset and create lag features\n",
    "    df_residual = build_residual_dataset(df_city, prophet_model)\n",
    "    df_supervised = create_lag_features(\n",
    "        df_residual, \n",
    "        target_col='residual',\n",
    "        max_lag=CONFIG[\"max_lag\"]\n",
    "    )\n",
    "\n",
    "    if df_supervised.empty:\n",
    "        LOGGER.warning(f\"Residual dataset for {city} is empty after lagging. Skipping city.\")\n",
    "        continue\n",
    "\n",
    "    # 3) Train RandomForest on residuals\n",
    "    rf_model, feature_cols = tune_residual_model(\n",
    "        df_supervised=df_supervised,\n",
    "        param_dist=CONFIG[\"rf_param_dist\"],\n",
    "        n_iter=CONFIG[\"n_iter_rf_random_search\"],\n",
    "        cv_splits=CONFIG[\"cv_splits\"],\n",
    "        random_state=CONFIG[\"random_state\"]\n",
    "    )\n",
    "\n",
    "    # 4) Create the hybrid forecast for the default target_year\n",
    "    target_year = CONFIG[\"target_year\"]\n",
    "    try:\n",
    "        hybrid_forecast = create_hybrid_forecast(\n",
    "            prophet_model=prophet_model,\n",
    "            rf_model=rf_model,\n",
    "            df_supervised=df_supervised,\n",
    "            feature_cols=feature_cols,\n",
    "            target_year=target_year,\n",
    "            max_lag=CONFIG[\"max_lag\"]\n",
    "        )\n",
    "    except ValueError as e:\n",
    "        LOGGER.warning(f\"Could not create forecast for city={city}, year={target_year}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "    # 5) Plot the final two‐subplot chart for this city and year, then save it\n",
    "    plot_full_forecast_and_save(city, hybrid_forecast, target_year)\n",
    "\n",
    "    # 6) Save forecast and models\n",
    "    forecast_filename = os.path.join(\n",
    "        CONFIG[\"output_dir\"],\n",
    "        f\"{city}_rainfall_forecast_{target_year}_hybrid.csv\"\n",
    "    )\n",
    "    hybrid_forecast.to_csv(forecast_filename, index=False)\n",
    "\n",
    "    prophet_model_path = os.path.join(CONFIG[\"model_dir\"], f\"{city}_prophet_model.pkl\")\n",
    "    rf_model_path = os.path.join(CONFIG[\"model_dir\"], f\"{city}_rf_residual_model.pkl\")\n",
    "\n",
    "    joblib.dump(prophet_model, prophet_model_path)\n",
    "    joblib.dump(rf_model, rf_model_path)\n",
    "\n",
    "    LOGGER.info(f\"Forecast saved to {forecast_filename}\")\n",
    "    LOGGER.info(f\"Prophet model saved to {prophet_model_path}\")\n",
    "    LOGGER.info(f\"RF model saved to {rf_model_path}\")\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# PREDICTION FUNCTION FOR A GIVEN CITY AND YEAR\n",
    "# ------------------------------------------------------------------------\n",
    "def predict_forecast(city: str, target_year: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Predicts the hybrid forecast for the given city and target_year.\n",
    "    It loads the saved models for the city, recomputes the residual dataset\n",
    "    and lag features from the historical data, then returns the forecast.\n",
    "    \"\"\"\n",
    "    df_all = load_data_multi_city(CONFIG[\"csv_path\"])\n",
    "    df_city = df_all[df_all[\"city_name\"] == city].copy()\n",
    "    if df_city.shape[0] < 2:\n",
    "        raise ValueError(f\"Not enough data for city '{city}'.\")\n",
    "\n",
    "    prophet_model_path = os.path.join(CONFIG[\"model_dir\"], f\"{city}_prophet_model.pkl\")\n",
    "    rf_model_path = os.path.join(CONFIG[\"model_dir\"], f\"{city}_rf_residual_model.pkl\")\n",
    "    if not os.path.exists(prophet_model_path) or not os.path.exists(rf_model_path):\n",
    "        raise FileNotFoundError(f\"Saved models for city '{city}' not found.\")\n",
    "    \n",
    "    prophet_model = joblib.load(prophet_model_path)\n",
    "    rf_model = joblib.load(rf_model_path)\n",
    "    \n",
    "    # Build residual dataset and create lag features\n",
    "    df_residual = build_residual_dataset(df_city, prophet_model)\n",
    "    df_supervised = create_lag_features(df_residual, target_col='residual', max_lag=CONFIG[\"max_lag\"])\n",
    "    if df_supervised.empty:\n",
    "        raise ValueError(f\"No valid residual data for city '{city}' after lagging.\")\n",
    "    \n",
    "    feature_cols = [c for c in df_supervised.columns if 'lag_' in c or 'day_of_' in c]\n",
    "    \n",
    "    # Create hybrid forecast\n",
    "    forecast = create_hybrid_forecast(prophet_model=prophet_model,\n",
    "                                      rf_model=rf_model,\n",
    "                                      df_supervised=df_supervised,\n",
    "                                      feature_cols=feature_cols,\n",
    "                                      target_year=target_year,\n",
    "                                      max_lag=CONFIG[\"max_lag\"])\n",
    "    return forecast\n",
    "\n",
    "def plot_full_forecast(city: str, forecast_df: pd.DataFrame, target_year: int):\n",
    "    \"\"\"\n",
    "    Plots a full forecast chart:\n",
    "      - Top subplot: observed history with Prophet forecast (with uncertainty band)\n",
    "        and Hybrid forecast.\n",
    "      - Bottom subplot: Monthly average of the Hybrid forecast.\n",
    "      \n",
    "    The function loads historical data for the city to plot the observed values.\n",
    "    \"\"\"\n",
    "    # Load historical data for the city\n",
    "    df_all = load_data_multi_city(CONFIG[\"csv_path\"])\n",
    "    df_city = df_all[df_all[\"city_name\"] == city].copy()\n",
    "    if df_city.empty:\n",
    "        print(f\"No historical data found for city {city}.\")\n",
    "        return\n",
    "\n",
    "    # Ensure the forecast dataframe's ds column is datetime\n",
    "    if not pd.api.types.is_datetime64_any_dtype(forecast_df['ds']):\n",
    "        forecast_df['ds'] = pd.to_datetime(forecast_df['ds'])\n",
    "    \n",
    "    # Filter forecast for the target year\n",
    "    forecast_year = forecast_df[forecast_df['ds'].dt.year == target_year].copy()\n",
    "    if forecast_year.empty:\n",
    "        print(f\"No forecast data found for the year {target_year}.\")\n",
    "        return\n",
    "\n",
    "    # Get the forecast start date\n",
    "    forecast_start = forecast_year['ds'].min()\n",
    "\n",
    "    # For observed data, only plot history up to the forecast start\n",
    "    observed = df_city[df_city['ds'] < forecast_start]\n",
    "\n",
    "    # Decide which columns to use\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(12, 8), sharex=False)\n",
    "\n",
    "    # --- Top subplot: Time series with observed data, Prophet forecast and Hybrid forecast ---\n",
    "    ax1 = axes[0]\n",
    "    ax1.set_title(f\"Rainfall Forecast for {city} ({target_year})\")\n",
    "\n",
    "    # Plot observed data\n",
    "    ax1.plot(observed['ds'], observed['y'], label='Observed (History)', color='black')\n",
    "\n",
    "    # Plot Prophet uncertainty band if available\n",
    "    if 'yhat_lower' in forecast_year.columns and 'yhat_upper' in forecast_year.columns:\n",
    "        ax1.fill_between(\n",
    "            forecast_year['ds'],\n",
    "            forecast_year['yhat_lower'],\n",
    "            forecast_year['yhat_upper'],\n",
    "            color='gray',\n",
    "            alpha=0.2,\n",
    "            label='Prophet Uncertainty'\n",
    "        )\n",
    "\n",
    "    # Plot Prophet forecast\n",
    "    ax1.plot(\n",
    "        forecast_year['ds'], \n",
    "        forecast_year['yhat'], \n",
    "        label='Prophet Forecast', \n",
    "        linestyle='--', \n",
    "        color='blue'\n",
    "    )\n",
    "\n",
    "    # Plot Hybrid forecast\n",
    "    ax1.plot(\n",
    "        forecast_year['ds'], \n",
    "        forecast_year['yhat_hybrid'], \n",
    "        label='Hybrid Forecast', \n",
    "        color='red'\n",
    "    )\n",
    "\n",
    "    ax1.set_ylabel(\"Rainfall (mm)\")\n",
    "    ax1.legend(loc='best')\n",
    "\n",
    "    # --- Bottom subplot: Monthly average of Hybrid forecast ---\n",
    "    ax2 = axes[1]\n",
    "    ax2.set_title(f\"Monthly Average Hybrid Forecast ({target_year})\")\n",
    "    forecast_year['month'] = forecast_year['ds'].dt.month\n",
    "    monthly_avg = forecast_year.groupby('month')['yhat_hybrid'].mean().reset_index().rename(columns={'yhat_hybrid': 'avg_forecast'})\n",
    "    ax2.bar(monthly_avg['month'], monthly_avg['avg_forecast'])\n",
    "    ax2.set_xlabel(\"Month\")\n",
    "    ax2.set_ylabel(\"Avg Rainfall (mm)\")\n",
    "    ax2.set_xticks(range(1, 13))\n",
    "    ax2.set_xticklabels([f\"{m:02d}\" for m in range(1, 13)])\n",
    "    ax2.set_xlim([0.5, 12.5])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# EXAMPLE USAGE\n",
    "# ------------------------------------------------------------------------\n",
    "# Example: Predict for a single city and single year\n",
    "# (Uncomment and run in your environment)\n",
    "forecast_for_city = predict_forecast(\"Kurunegala\", 2027)\n",
    "print(forecast_for_city.head())\n",
    "plot_full_forecast(\"Kurunegala\", forecast_for_city, 2027)\n",
    "\n",
    "# Example: Predict for multiple target years for Nuwara Eliya\n",
    "target_years = [2025, 2026, 2027]\n",
    "city = \"Nuwara Eliya\"\n",
    "for year in target_years:\n",
    "    forecast_for_city = predict_forecast(city, year)\n",
    "    print(f\"\\nForecast for {city} in {year}:\")\n",
    "    print(forecast_for_city.head())\n",
    "    \n",
    "    csv_filename = os.path.join(CONFIG[\"output_dir\"], f\"{city}_rainfall_forecast_{year}_hybrid.csv\")\n",
    "    forecast_for_city.to_csv(csv_filename, index=False)\n",
    "    print(f\"Forecast saved to {csv_filename}\")\n",
    "    \n",
    "    plot_full_forecast(city, forecast_for_city, year)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
